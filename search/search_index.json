{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Emissions Downscaler","text":"<p>Homepage for Photochemical Emissions Downscaler</p> <p>For installation and configuration instrucations, see the Installation page. </p> <p>For basic usage see the Getting Started page.</p>"},{"location":"about/","title":"About","text":""},{"location":"getting_started/","title":"Getting Started","text":"<p>After completing the necessary installation and configuration steps,</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#getting-the-code","title":"Getting the code","text":"<p>The most up-to-date version of this repository including all tutorial data can be downloaded locally using git. You can \"get git\" onto your local machine directly from the git website, or it can be installed within a conda environment using <code>conda install -c conda-forge git</code>. Either way, once git is configured, you can download everything you need to run these examples with</p> <pre><code>git clone https://github.com/needham-michael/emiss_downscale.git\n</code></pre> <p>This will create a directory called <code>/emiss_downscale</code> on your local machine.</p>"},{"location":"installation/#preparing-the-python-environment","title":"Preparing the python environment","text":"<p>The <code>environment.yml</code> file includes instructions for recreating the same conda environment (also named <code>emiss_downscale</code>) used to develop and run these notebooks. Assuming conda has been installed locally and initialized for the user's shell, the environment can be recreated by running the following command from within the base directory</p> <pre><code>conda env create -f environment.yml`\n\n# Then, activate the environment with\nconda activate emiss_downscale\n</code></pre>"},{"location":"installation/#installing-the-project-package","title":"Installing the project package","text":"<p>You will need to install the project source code into the <code>emiss_downscale</code> conda environment by running the following command from the root <code>./emiss_downscale</code> folder (make sure that the correct conda environment is selected):</p> <pre><code>(emiss_downscale) pip install .\n</code></pre> <p>This will install the package source code (<code>/emiss_downscale/downscaler</code>) into the active conda environment.</p>"},{"location":"installation/#configuring-jupyter-notebooks","title":"Configuring Jupyter Notebooks","text":""},{"location":"installation/#usage-with-jupyterhub","title":"Usage with JupyterHub","text":"<p>Once the environment has been created, Jupyter needs to be configured to execute the notebooks using the environment. This requires using the ipykernel package, which was included in the <code>environment.yml</code> file. From the terminal window, run</p> <pre><code>python3 -m ipykernel install --user --name=cmaq_pyenv --display-name=\"Python3 (cmaq_pyenv)\"\n</code></pre> <p>Then, select the appropriate tile from the jupyterlab launcher.</p>"},{"location":"installation/#usage-with-jupyterlab-or-jupyter-notebooks","title":"Usage with JupyterLab or Jupyter Notebooks","text":"<p>Ensure the environment is active and run one of the following commands to launch a jupyter server.</p> <pre><code># For jupyter lab\n(emiss_downscale) jupyter lab\n\n# For the classic notebooks\n(emiss_downscale) jupyter notebook\n</code></pre> <p>Next Up: Getting Started</p>"},{"location":"usage_offline/","title":"Offline Usage","text":"<p>An example using the <code>downscale.allocate</code> module to downscale 12 km emissions to a finer 4 km grid, based on the spatial structure of existing 4 km emissions. </p>"},{"location":"usage_offline/#imports","title":"Imports","text":"<pre><code>import xarray as xr\n\nfrom downscaler.utils.cmaq import get_cmaq_metadata, get_cmaq_projection\nfrom downscaler.utils.xarray import update_datetime_year\nfrom downscaler.allocate.allocate import (\n    downscale_coarse_emissions,\n    coarsen_finescale_emissions,\n)\n</code></pre>"},{"location":"usage_offline/#read-data","title":"Read Data","text":"<pre><code>filename_fine = \"../sandbox_data/emis_mole_rwc_20170601_4LMOS3_2017gb_4km_17j.ncf\"\nfilename_coarse = (\n    \"../sandbox_data/emis_mole_rwc_20210601_12US1_cmaq_cb6ae7_2021hb_cb6_21k.ncf\"\n)\n\n# Note that datasets are associated with different years, so update to use the\n# same year for easier comparison.\n\nupdated_year = 1901\ndata_fine = update_datetime_year(\n    get_cmaq_metadata(xr.open_dataset(filename_fine)), updated_year=updated_year\n)\n\ndata_coarse = update_datetime_year(\n    get_cmaq_metadata(xr.open_dataset(filename_coarse)), updated_year=updated_year\n)\n\n\nproj_fine = get_cmaq_projection(data_fine)\nproj_coarse = get_cmaq_projection(data_coarse)\n</code></pre>"},{"location":"usage_offline/#perform-downscaling","title":"Perform Downscaling","text":"<pre><code>%%time\n\nfield = \"NO2\"\n\nda_fine = data_fine[field].isel(LAY=0)\nda_coarse = da_coarse = data_coarse[field].isel(LAY=0)\n\nda_dscale = downscale_coarse_emissions(\n    da_fine=da_fine,\n    da_coarse=da_coarse,\n    proj_fine=proj_fine,\n    proj_coarse=proj_coarse,\n    grid_factor=3,\n)\n</code></pre> <pre><code>CPU times: user 40.4 ms, sys: 8.85 ms, total: 49.2 ms\nWall time: 269 ms\n</code></pre> <p>For comparison purposes, also upscale the fine-scale emissions to the coarse grid</p> <pre><code>da_upscale = coarsen_finescale_emissions(\n    da_fine=da_fine,\n    grid_factor=3,\n)\n</code></pre>"},{"location":"usage_offline/#visualize-output","title":"Visualize Output","text":"<pre><code>import matplotlib.pyplot as plt\nimport cartopy.feature as cf\n</code></pre> <pre><code># =============================================================================\n# Figure Specifications\n# =============================================================================\n\n# Area of 4km and 12km gridcells to calculate emission rate per sq km\narea4k = 4 * 4\narea12k = 12 * 12\n\nitime = 0\n\n# Colorbar specifications\ncmap = \"Spectral_r\"\nvmin = 0\nvmax = 1e-6\n\nextent = [da_fine.x.min(), da_fine.x.max(), da_fine.y.min(), da_fine.y.max()]\n\n# =============================================================================\n# Create the Figure\n# =============================================================================\n\nfig, axs = plt.subplots(\n    ncols=4, subplot_kw=dict(projection=proj_fine), dpi=600, layout=\"constrained\"\n)\n\nax1, ax2, ax3, ax4 = axs\n\ncs = ax1.pcolormesh(\n    da_fine.x,\n    da_fine.y,\n    da_fine.isel(time=itime) / area4k,\n    transform=proj_fine,\n    vmin=vmin,\n    vmax=vmax,\n    cmap=cmap,\n)\n\nax2.pcolormesh(\n    da_dscale.x,\n    da_dscale.y,\n    da_dscale.isel(time=itime) / area4k,\n    transform=proj_fine,\n    vmin=vmin,\n    vmax=vmax,\n    cmap=cmap,\n)\n\nax3.pcolormesh(\n    da_upscale.x,\n    da_upscale.y,\n    da_upscale.isel(time=itime) / area12k,\n    transform=proj_fine,\n    vmin=vmin,\n    vmax=vmax,\n    cmap=cmap,\n)\n\nax4.pcolormesh(\n    da_coarse.x,\n    da_coarse.y,\n    da_coarse.isel(time=itime) / area12k,\n    transform=proj_coarse,\n    vmin=vmin,\n    vmax=vmax,\n    cmap=cmap,\n)\n\n# -----------------------------------------------------------------------------\n# Add Colorbar, Titles, and Outlines of US States\n# -----------------------------------------------------------------------------\n\ncbar = fig.colorbar(cs, ax=axs, location=\"bottom\")\ncbar.set_label(\"NO2 Emissions (moles/s/km2)\")\n\nax1.set_title(\"2017: 4km Native\", fontsize=8, loc=\"left\")\nax2.set_title(\"2021: 4km Downscaled\", fontsize=8, loc=\"left\")\nax3.set_title(\"2017: 12km Upscaled\", fontsize=8, loc=\"left\")\nax4.set_title(\"2021: 12km Native\", fontsize=8, loc=\"left\")\n\nfor ax in axs:\n    ax.add_feature(cf.STATES.with_scale(\"110m\"), linewidth=0.5)\n    ax.set_extent(extent, crs=proj_fine)\n\nplt.show()\n</code></pre> <pre><code>\n</code></pre> <p>See also online usage</p>"},{"location":"usage_online/","title":"Online Usage","text":"<p>See also offline usage</p> <p>pydscale</p>"},{"location":"api/allocate/","title":"Allocate","text":"<p>Module controlling spatially-informed downscaling of emissions</p>"},{"location":"api/allocate/#downscaler.allocate.allocate.coarsen_finescale_emissions","title":"<code>coarsen_finescale_emissions(da_fine, grid_factor=3, agg=np.sum)</code>","text":"<p>Upscale fine-gridded emissions to a coarser grid</p> <p>Parameters:</p> Name Type Description Default <code>da_fine</code> <code>DataArray or Dataset</code> <p>Fine scale emissions. Units of <code>da</code> determine the appropriate choice of <code>agg</code></p> required <code>grid_factor</code> <code>int</code> <p>Number of gridcells in the x- and y-dimensions to combine to generate the coarse scale emissions.</p> <code>3</code> <code>agg</code> <code>function</code> <p>Function used to combine fine scale emissions onto the coarse grid.</p> <code>np.sum</code> <p>Returns:</p> Name Type Description <code>da_coarse</code> <code>same type as `da_fine`</code> <p>Coarse scale emissions</p> Notes <p>Note on the choice of the <code>agg</code> function:     It is important to conserve mass when coarsening emissions from the     fine to the coarse grid.  If emissions are in units like     [moles / second], then np.sum is likely appropriate, while if instead     emissions are in units like [moles / second / km$^2$], then np.mean is     likely appropriate.</p> Source code in <code>downscaler/allocate/allocate.py</code> <pre><code>def coarsen_finescale_emissions(da_fine, grid_factor=3, agg=np.sum):\n    \"\"\"Upscale fine-gridded emissions to a coarser grid\n\n    Parameters\n    ----------\n    da_fine : xr.DataArray or xr.Dataset\n        Fine scale emissions. Units of `da` determine the appropriate choice\n        of `agg`\n\n    grid_factor : int, default=3\n        Number of gridcells in the x- and y-dimensions to combine to generate\n        the coarse scale emissions.\n\n    agg : function, default=np.sum\n        Function used to combine fine scale emissions onto the coarse grid.\n\n    Returns\n    -------\n    da_coarse : same type as `da_fine`\n        Coarse scale emissions\n\n    Notes\n    -----\n    Note on the choice of the `agg` function:\n        It is important to conserve mass when coarsening emissions from the\n        fine to the coarse grid.  If emissions are in units like\n        [moles / second], then np.sum is likely appropriate, while if instead\n        emissions are in units like [moles / second / km$^2$], then np.mean is\n        likely appropriate.\n    \"\"\"\n\n    da_coarse = da_fine.coarsen(x=grid_factor, y=grid_factor).reduce(agg)\n    da_coarse = da_coarse.assign_attrs(\n        {\n            \"COARSEN\": f\"\"\"Emissions generated from fine to coarse scale by a factor of {grid_factor} in the x- and y-dimensions. Data aggregated with function: `{agg.__name__}`\"\"\"\n        }\n    )\n\n    return da_coarse\n</code></pre>"},{"location":"api/allocate/#downscaler.allocate.allocate.downscale_coarse_emissions","title":"<code>downscale_coarse_emissions(da_fine, da_coarse, proj_fine, proj_coarse, grid_factor=3, agg=np.sum)</code>","text":"<p>Downscale coarse emissions based on fine scale spatial information</p> <p>Parameters:</p> Name Type Description Default <code>da_fine</code> <code>DataArray or Dataset</code> <p>Emissions on a fine grid which will be used to estimate the spatial allocation of emissions between the coarse and fine scales.</p> required <code>da_coarse</code> <code>DataArray or Dataset</code> <p>Emissions on a coarse grid which will be downscaled to a finer grid based on the spatial distribution of emissions learned from <code>da_fine</code>.</p> required <code>proj_fine</code> <p>Map projections associated with <code>da_fine</code> and <code>da_coarse</code>, respectively</p> required <code>proj_coarse</code> <p>Map projections associated with <code>da_fine</code> and <code>da_coarse</code>, respectively</p> required <code>grid_factor</code> <code>int</code> <p>The number of <code>da_fine</code> gridcells which it within a single <code>da_coarse</code> gridcell.</p> <code>3</code> <code>agg</code> <code>function</code> <p>Aggregation function used to combine <code>da_fine</code> values when upscaling to the coarser grid. Whether <code>np.sum</code> or <code>np.mean</code> is appropriate is dependent on the units of the particular emission species. The default of <code>np.sum</code> is appropriate for emissions with units like [moles/second]</p> <code>np.sum</code> <p>Returns:</p> Name Type Description <code>da_dscale</code> <code>same type as da_coarse</code> <p>Downscaled emissions estimate based on the spatial distribution of emissions from <code>da_fine</code>.</p> Notes <p>The expected use case for this method is to take fine-scale gridded emissions from an older modeling platform (e.g., 2018 on a custom 4km grid) and use the spatial information associated with those emissions to estimate the fine-scale gridded emissions from a newer modeling platform (e.g., 2018 on a 12US1 grid).</p> Source code in <code>downscaler/allocate/allocate.py</code> <pre><code>def downscale_coarse_emissions(\n    da_fine, da_coarse, proj_fine, proj_coarse, grid_factor=3, agg=np.sum\n):\n    \"\"\"Downscale coarse emissions based on fine scale spatial information\n\n    Parameters\n    ----------\n    da_fine : xr.DataArray or xr.Dataset\n        Emissions on a fine grid which will be used to estimate the spatial\n        allocation of emissions between the coarse and fine scales.\n\n    da_coarse : xr.DataArray or xr.Dataset\n        Emissions on a coarse grid which will be downscaled to a finer grid\n        based on the spatial distribution of emissions learned from `da_fine`.\n\n    proj_fine, proj_coarse: cartopy.crs\n        Map projections associated with `da_fine` and `da_coarse`, respectively\n\n    grid_factor : int, default=3\n        The number of `da_fine` gridcells which it within a single `da_coarse`\n        gridcell.\n\n    agg : function, default=np.sum\n        Aggregation function used to combine `da_fine` values when upscaling to\n        the coarser grid. Whether `np.sum` or `np.mean` is appropriate is\n        dependent on the units of the particular emission species. The default\n        of `np.sum` is appropriate for emissions with units like [moles/second]\n\n    Returns\n    -------\n    da_dscale : same type as da_coarse\n        Downscaled emissions estimate based on the spatial distribution of\n        emissions from `da_fine`.\n\n    Notes\n    -----\n    The expected use case for this method is to take fine-scale gridded\n    emissions from an older modeling platform (e.g., 2018 on a custom 4km grid)\n    and use the spatial information associated with those emissions to estimate\n    the fine-scale gridded emissions from a newer modeling platform (e.g., 2018\n    on a 12US1 grid).\n    \"\"\"\n\n    # =========================================================================\n    # Step 1: Upscale the reference emissions from the fine to the coarse scale\n    # =========================================================================\n    # First, ensure that the x- and y-coordinates of the target and reference\n    # emissions use the same false easting and false northing\n    da_coarse = align_coordinates(\n        da_coarse, proj_start=proj_coarse, proj_final=proj_fine\n    )\n\n    # Upscale the reference emissions up to the same resolution as the\n    # target emissions; aggregate together using `agg`\n    da_fine_coarsened = coarsen_finescale_emissions(\n        da_fine, grid_factor=grid_factor, agg=agg\n    )\n\n    # =========================================================================\n    # Step 2: Calculate the fractional contribution to the total emissions from\n    #         the fine scale\n    # =========================================================================\n    # Calculate the fractional contribution that each fine-scale reference\n    # gridcell makes to the total emissions on the coarsened reference\n    # emissions\n    ref_contrib = fractional_contribution(da_fine=da_fine, da_coarse=da_fine_coarsened)\n\n    # =========================================================================\n    # Step 3: Use the fractional contribution to downscale the target emissions\n    #         onto the finer grid\n    # =========================================================================\n\n    # Interpolate the target emissions onto the finer grid using a nearest\n    # neighbor method so that the downscaling can be achieved using a simple\n    # array-wise multiplication. Note the need to call the internal\n    # _fill_perimeter function due to the specific implementation of the\n    # NN interpolation... see the associated docstring for that function\n    da_coarse_nn = da_coarse.interp_like(da_fine, method=\"nearest\")\n    da_coarse_nn = _fill_perimeter(da_coarse_nn)\n\n    # Finally, multiply the reference fraction and target NN arrays together\n    # to downscale the emissions\n    da_dscale = ref_contrib * da_coarse_nn\n\n    return da_dscale\n</code></pre>"},{"location":"api/allocate/#downscaler.allocate.allocate.fractional_contribution","title":"<code>fractional_contribution(da_fine, da_coarse)</code>","text":"<p>Calculate the fractional contribution of fine- to coarse-scale emissions</p> <p>Calculate the fraction of the total emissions within a coarse-scale gridcell that are due to each fine-scale gridcell that falls within the coarse-scale gridcell.</p> <p>Parameters:</p> Name Type Description Default <code>da_coarse</code> <code>same type as `da_fine` xr.DataArray or xr.Dataset</code> <p>Coarse scale emissions.</p> required <p>Returns:</p> Name Type Description <code>da_fractional_contribution</code> <code>same type as `da_fine`</code> <p>Fractional contribution of each fine scale emissions to the total emissions within the coarse scale. Due to divide by zero issues, if the total emissions within a coarse scale gridcell are zero, then the emission fraction for the fine gridcells within the coarse cell are set equal to zero.</p> Notes <p>The implementation using xarray.DataArray.interp_like(...,method='nearest') leads to NaN values along the perimeter because of its reliance on scipy.interpolate.interpn, which interprets these perimeter values as outside of the domain.</p> Source code in <code>downscaler/allocate/allocate.py</code> <pre><code>def fractional_contribution(da_fine, da_coarse):\n    \"\"\"Calculate the fractional contribution of fine- to coarse-scale emissions\n\n    Calculate the fraction of the total emissions within a coarse-scale\n    gridcell that are due to each fine-scale gridcell that falls within the\n    coarse-scale gridcell.\n\n    Parameters\n    ----------\n     da_fine : xr.DataArray or xr.Dataset\n        Fine scale emissions.\n\n    da_coarse : same type as `da_fine` xr.DataArray or xr.Dataset\n        Coarse scale emissions.\n\n    Returns\n    -------\n    da_fractional_contribution: same type as `da_fine`\n        Fractional contribution of each fine scale emissions to the total\n        emissions within the coarse scale. Due to divide by zero issues, if\n        the total emissions within a coarse scale gridcell are zero, then the\n        emission fraction for the fine gridcells within the coarse cell are\n        set equal to zero.\n\n    Notes\n    -----\n    The implementation using xarray.DataArray.interp_like(...,method='nearest')\n    leads to NaN values along the perimeter because of its reliance on\n    scipy.interpolate.interpn, which interprets these perimeter values as\n    outside of the domain.\n\n    \"\"\"\n\n    # Regrid the coarse scale emissions back down to the fine scale so that the\n    # fractional contribution calculation can be performed array-wise. See note\n    # on filling NaN values along perimeter\n    da_coarse_regridded = da_coarse.interp_like(da_fine, method=\"nearest\")\n    da_coarse_regridded = _fill_perimeter(da_coarse_regridded)\n\n    da_fractional_contribution = da_fine / da_coarse_regridded\n\n    return da_fractional_contribution.fillna(0)\n</code></pre>"},{"location":"api/allocate/#downscaler.allocate.allocate.parse_args","title":"<code>parse_args()</code>","text":"<p>Parse Command Line Arguments and enforce any necessary conditions</p> Source code in <code>downscaler/allocate/allocate.py</code> <pre><code>def parse_args():\n    \"\"\"Parse Command Line Arguments and enforce any necessary conditions\"\"\"\n    parser = argparse.ArgumentParser()\n\n    parser.add_argument(\n        \"fine\",\n        help=\"emissions on fine grid, will be used to downscale coarse emissions\",\n    )\n    parser.add_argument(\n        \"coarse\", help=\"emissions on coarse grid, will be downscaled to fine grid\"\n    )\n\n    parser.add_argument(\n        \"--out\", help=\"output file for downscaled emissions\", default=\"./out.ncf\"\n    )\n\n    parser.add_argument(\n        \"--grid-factor\",\n        help=\"Ratio of coarse grid spacing to fine grid spacing. Must be an odd integer.\",\n        default=3,\n        type=int,\n        dest=\"gridfactor\",\n    )\n\n    parser.add_argument(\n        \"--data-vars\",\n        help=\"Variable names for spatial downscaling\",\n        action=\"store\",\n        default=None,\n        nargs=\"*\",\n        dest=\"datavars\",\n    )\n\n    parser.add_argument(\n        \"--output-year\",\n        help=\"Set the year of the output file\",\n        default=1901,\n        type=int,\n        dest=\"outputyear\",\n    )\n\n    parser.add_argument(\n        \"-d\",\n        \"--debug\",\n        help=\"Print lots of debugging statements\",\n        action=\"store_const\",\n        dest=\"loglevel\",\n        const=logging.DEBUG,\n        default=logging.WARNING,\n    )\n\n    parser.add_argument(\n        \"-v\",\n        \"--verbose\",\n        help=\"increase output verbosity\",\n        action=\"store_const\",\n        dest=\"loglevel\",\n        const=logging.INFO,\n    )\n\n    parser.add_argument(\n        \"-p\",\n        \"--progress-bar\",\n        help=\"Show a progress bar for downscaling vars\",\n        action=\"store_true\",\n        dest=\"progressbar\",\n    )\n\n    args = parser.parse_args()\n\n    if args.gridfactor % 2 == 0:\n        raise ValueError(\n            f\"--grid-factor={args.gridfactor} Is not an odd integer. Exiting.\"\n        )\n\n    return args\n</code></pre>"},{"location":"api/cmaq/","title":"CMAQ","text":"<p>Utility functions for working with CMAQ output</p>"},{"location":"api/cmaq/#downscaler.utils.cmaq.drop_cmaq_metadata","title":"<code>drop_cmaq_metadata(dset)</code>","text":"<p>Remove metadata and reset to original IOAPI conventions</p> <p>Drop all metadata additions made to dataset by get_cmaq_metadata</p> <p>Parameters:</p> Name Type Description Default <code>dset</code> <code>Dataset</code> <p>result of calling xr.open_dataset() on a file in cmaq format</p> required <p>Returns:</p> Name Type Description <code>dset</code> <code>Dataset</code> <p>the same input dataset, but coordinate arrays dropped</p> See Also <p>get_cmaq_metadata</p> Source code in <code>downscaler/utils/cmaq.py</code> <pre><code>def drop_cmaq_metadata(dset):\n    \"\"\"Remove metadata and reset to original IOAPI conventions\n\n    Drop all metadata additions made to dataset by get_cmaq_metadata\n\n    Parameters\n    ----------\n    dset : xarray.Dataset\n        result of calling xr.open_dataset() on a file in cmaq format\n\n    Returns\n    -------\n    dset : xarray.Dataset\n        the same input dataset, but coordinate arrays dropped\n\n    See Also\n    --------\n    get_cmaq_metadata\n    \"\"\"\n\n    # Drop projection-aware x and y coordinates, and datetime-aware time coord\n    dset = dset.drop_vars([\"x\", \"y\", \"time\"])\n\n    # Rename back to IOAPI convention\n    dset = dset.rename_dims(\n        {\n            \"time\": \"TSTEP\",\n            \"x\": \"COL\",\n            \"y\": \"ROW\",\n        }\n    )\n\n    # Ensure there is a length-1 \"LAY\" dimension\n    if \"LAY\" not in list(dset.dims):\n        dset = dset.expand_dims(dim=\"LAY\", axis=1)\n\n    return dset\n</code></pre>"},{"location":"api/cmaq/#downscaler.utils.cmaq.get_cmaq_datetime","title":"<code>get_cmaq_datetime(dset, is_jday=True)</code>","text":"<p>Generate datetime coordinate array for cmaq-formatted data</p> <p>Interpret attributes of the input file to generate datetime coordinate array based on the number of timesteps, the size of the timestep, and the starting date and time</p> <p>Parameters:</p> Name Type Description Default <code>dset</code> <code>Dataset</code> <p>result of calling xr.open_dataset() on a file in cmaq format</p> required <code>is_jday</code> <code>bool</code> <p>flag to indicate if input dates use the Julian (YYYYJJJ) or the Gregorian (YYYYMMDD) calendar format. Note that even if is_jday=True, the resulting datetime coordinate array will use the defauly pandas gregorian calendar. In other words, this flag is only used to interpret input dates, not to set output dates.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>datetimes</code> <code>Series</code> <p>datetime coordinate array, parsed to pandas gregorian datetime format.</p> Source code in <code>downscaler/utils/cmaq.py</code> <pre><code>def get_cmaq_datetime(dset, is_jday=True):\n    \"\"\"Generate datetime coordinate array for cmaq-formatted data\n\n    Interpret attributes of the input file to generate datetime\n    coordinate array based on the number of timesteps, the size of the\n    timestep, and the starting date and time\n\n    Parameters\n    ----------\n    dset : xarray.Dataset\n        result of calling xr.open_dataset() on a file in cmaq format\n\n    is_jday : bool, default=True\n        flag to indicate if input dates use the Julian (YYYYJJJ) or the\n        Gregorian (YYYYMMDD) calendar format. Note that even if\n        is_jday=True, the resulting datetime coordinate array will use\n        the defauly pandas gregorian calendar. In other words, this\n        flag is only used to interpret input dates, not to set output\n        dates.\n\n    Returns\n    -------\n    datetimes : pandas.Series\n        datetime coordinate array, parsed to pandas gregorian datetime\n        format.\n    \"\"\"\n    from pandas import to_datetime\n\n    ntstep = len(dset.TSTEP)\n\n    times = np.arange(\n        dset.attrs[\"STIME\"], dset.attrs[\"TSTEP\"] * ntstep, dset.attrs[\"TSTEP\"]\n    )\n\n    start_date = dset.attrs[\"SDATE\"]\n    date_inc = -1\n    datetimes = []\n\n    for time in times % 240000:\n        if time == 0:\n            date_inc += 1\n\n        datetimes.append(f\"{start_date+date_inc}T{time:0&gt;6}\")\n\n    if is_jday:\n        date_format = \"%Y%jT%H%M%S\"\n    else:\n        date_format = \"%Y%m%dT%H%M%S\"\n\n    datetimes = to_datetime(datetimes, format=date_format)\n\n    return datetimes\n</code></pre>"},{"location":"api/cmaq/#downscaler.utils.cmaq.get_cmaq_metadata","title":"<code>get_cmaq_metadata(dset, is_jday=True, return_proj=False)</code>","text":"<p>Interpret and add coordinate arrays to cmaq-formatted data</p> <p>Interpret attributes of the input file to generate datetime coordinate array based on the number of timesteps, the size of the timestep, and the starting date and time</p> <p>Parameters:</p> Name Type Description Default <code>dset</code> <code>Dataset</code> <p>result of calling xr.open_dataset() on a file in cmaq format</p> required <code>is_jday</code> <code>bool</code> <p>parameter passed to get_cmaq_datetime()</p> <code>True</code> <p>Returns:</p> Name Type Description <code>dset</code> <code>Dataset</code> <p>the same input dataset, but with added coordinate arrays</p> <code>proj_lamb</code> <code>LambertConformal</code> <p>a cartopy Lambert conformal conic projection with parameters set by the input dataset attributes, for use in plotting</p> See Also <p>drop_cmaq_metadata</p> Source code in <code>downscaler/utils/cmaq.py</code> <pre><code>def get_cmaq_metadata(dset, is_jday=True, return_proj=False):\n    \"\"\"Interpret and add coordinate arrays to cmaq-formatted data\n\n    Interpret attributes of the input file to generate datetime\n    coordinate array based on the number of timesteps, the size of the\n    timestep, and the starting date and time\n\n    Parameters\n    ----------\n    dset : xarray.Dataset\n        result of calling xr.open_dataset() on a file in cmaq format\n\n    is_jday : bool, default=True\n        parameter passed to get_cmaq_datetime()\n\n    Returns\n    -------\n    dset : xarray.Dataset\n        the same input dataset, but with added coordinate arrays\n\n    proj_lamb : cartopy.crs.LambertConformal\n        a cartopy Lambert conformal conic projection with parameters\n        set by the input dataset attributes, for use in plotting\n\n    See Also\n    --------\n    drop_cmaq_metadata\n    \"\"\"\n\n    # Get coordinate arrays associated with the x-, y-, and time-dimensions\n    xcoords, ycoords = get_cmaq_xy(dset)\n    datetimes = get_cmaq_datetime(dset, is_jday=is_jday)\n\n    # Add the coordinate arrays and rename the output\n    dset = dset.assign_coords({\"COL\": xcoords, \"ROW\": ycoords, \"TSTEP\": datetimes})\n    dset = dset.rename({\"ROW\": \"y\", \"COL\": \"x\", \"TSTEP\": \"time\"})\n\n    if return_proj:\n\n        proj = get_cmaq_projection(dset)\n\n        return dset, proj\n\n    return dset\n</code></pre>"},{"location":"api/cmaq/#downscaler.utils.cmaq.get_cmaq_projection","title":"<code>get_cmaq_projection(dset, proj_type='lambert')</code>","text":"<p>Create a cartopy lambert projection object from dataset metadata</p> Source code in <code>downscaler/utils/cmaq.py</code> <pre><code>def get_cmaq_projection(dset, proj_type=\"lambert\"):\n    \"\"\"Create a cartopy lambert projection object from dataset metadata\"\"\"\n\n    if proj_type == \"lambert\":\n        # Generate the projection\n        proj = cartopy.crs.LambertConformal(\n            central_latitude=dset.attrs[\"YCENT\"],\n            central_longitude=dset.attrs[\"XCENT\"],\n            standard_parallels=(dset.attrs[\"P_ALP\"], dset.attrs[\"P_BET\"]),\n            false_easting=-dset.attrs[\"XORIG\"],\n            false_northing=-dset.attrs[\"YORIG\"],\n        )\n\n    elif (proj_type == \"mercator\") or (proj_type == \"polar\"):\n        raise NotImplementedError(f'projection: \"{proj_type}\" not yet implemented')\n\n    else:\n        raise ValueError(\n            f\"\"\"\n        Invalid projection: {proj_type}.\n        Choose a valid projection: [\\'lambert\\', \\'mercator\\', \\'polar\\']\n        \"\"\"\n        )\n\n    return proj\n</code></pre>"},{"location":"api/cmaq/#downscaler.utils.cmaq.get_cmaq_xy","title":"<code>get_cmaq_xy(dset)</code>","text":"<p>Generate x and y coordinate arrays for cmaq-formatted data</p> <p>Interpret attributes of the input file to generate x and y coordinate arrays based on the number of gridcells in the x- and y-directions, and the size of the gridcells in in those directions (which will typically be identical, but in general could be different).</p> <p>Parameters:</p> Name Type Description Default <code>dset</code> <code>Dataset</code> <p>result of calling xr.open_dataset() on a netcdf file in cmaq format</p> required <p>Returns:</p> Name Type Description <code>xcoords</code> <code>array</code> <p>coordinate array for the x dimension</p> <code>ycoords</code> <code>array</code> <p>coordinate array for the y dimension</p> Source code in <code>downscaler/utils/cmaq.py</code> <pre><code>def get_cmaq_xy(dset):\n    \"\"\"Generate x and y coordinate arrays for cmaq-formatted data\n\n    Interpret attributes of the input file to generate x and y\n    coordinate arrays based on the number of gridcells in the x- and\n    y-directions, and the size of the gridcells in in those directions\n    (which will typically be identical, but in general could be\n    different).\n\n    Parameters\n    ----------\n    dset : xarray.Dataset\n        result of calling xr.open_dataset() on a netcdf file in cmaq format\n\n    Returns\n    -------\n    xcoords : numpy.array\n        coordinate array for the x dimension\n\n    ycoords : numpy.array\n        coordinate array for the y dimension\n    \"\"\"\n\n    xcoords = np.arange(\n        0, (dset.attrs[\"XCELL\"] * dset.attrs[\"NCOLS\"]), dset.attrs[\"XCELL\"]\n    )\n\n    ycoords = np.arange(\n        0, dset.attrs[\"YCELL\"] * dset.attrs[\"NROWS\"], dset.attrs[\"YCELL\"]\n    )\n\n    return xcoords, ycoords\n</code></pre>"},{"location":"api/xarray/","title":"Xarray","text":"<p>Utility functions for working with xarray data types</p>"},{"location":"api/xarray/#downscaler.utils.xarray.align_coordinates","title":"<code>align_coordinates(da, proj_start, proj_final)</code>","text":"<p>Align coordinates of a xr.DataArray to a new coordinate system</p> <p>Update the x and y coordinates based on the difference in the false easting and false northing between the two coordinate systems</p> <p>Parameters:</p> Name Type Description Default <code>da</code> <code>Dataset or DataArray</code> <p>xarray object for which coordinates will be aligned with a new coordinate system</p> required <code>proj_final</code> <code>crs</code> <p>Coordinate system associated with <code>da</code></p> required <code>proj_start</code> <code>crs</code> <p>Target coordinate system for the coordinate alignment</p> required <p>Returns:</p> Name Type Description <code>da_aligned</code> <code>Dataset or DataArray</code> <p>The input <code>da</code> after coordinate arrays have been updated based on parameters of <code>proj_final</code></p> <p>Raises:</p> Type Description <code>Raises an error if `proj_start` and `proj_final` have different parameters</code> Source code in <code>downscaler/utils/xarray.py</code> <pre><code>def align_coordinates(da, proj_start, proj_final):\n    \"\"\"Align coordinates of a xr.DataArray to a new coordinate system\n\n    Update the x and y coordinates based on the difference in the false easting\n    and false northing between the two coordinate systems\n\n    Parameters\n    ----------\n\n    da : xr.Dataset or xr.DataArray\n        xarray object for which coordinates will be aligned with a new\n        coordinate system\n\n    proj_final : cartopy.crs\n        Coordinate system associated with `da`\n\n    proj_start : cartopy.crs\n        Target coordinate system for the coordinate alignment\n\n    Returns\n    -------\n\n    da_aligned : xr.Dataset or xr.DataArray\n        The input `da` after coordinate arrays have been updated based on\n        parameters of `proj_final`\n\n    Raises\n    ------\n    Raises an error if `proj_start` and `proj_final` have different parameters\n    \"\"\"\n\n    # -------------------------------------------------------------------------\n    # Ensure all parameters of the two map projections are identical with the\n    # excpetion of the false easting and false northing\n    # -------------------------------------------------------------------------\n    bad_vals = {}\n    for key in proj_start.proj4_params.keys():\n        if key not in [\"x_0\", \"y_0\"]:\n            val_start = proj_start.proj4_params[key]\n            val_final = proj_final.proj4_params[key]\n            if val_final != val_start:\n                bad_vals[key] = [val_start, val_final]\n\n    if len(bad_vals.keys()) &gt; 0:\n        raise ValueError(f\"INCOMPATIBLE MAP PROJECTIONS. {bad_vals=}\")\n\n    # -------------------------------------------------------------------------\n    # Perform the coordinate adjustment\n    # -------------------------------------------------------------------------\n    false_easting = {\n        \"start\": proj_start.proj4_params[\"x_0\"],\n        \"final\": proj_final.proj4_params[\"x_0\"],\n    }\n\n    false_northing = {\n        \"start\": proj_start.proj4_params[\"y_0\"],\n        \"final\": proj_final.proj4_params[\"y_0\"],\n    }\n\n    x_final = da[\"x\"] - false_easting[\"start\"] + false_easting[\"final\"]\n    y_final = da[\"y\"] - false_northing[\"start\"] + false_northing[\"final\"]\n\n    da_aligned = da.copy(deep=True)\n    da_aligned = da_aligned.assign_coords({\"x\": x_final, \"y\": y_final})\n\n    return da_aligned\n</code></pre>"},{"location":"api/xarray/#downscaler.utils.xarray.display_vars","title":"<code>display_vars(dset, var_dsec='var_desc', str_incl=None, str_excl=None)</code>","text":"<p>Displays variables, units, and descriptions of an xarray dataset</p> <p>Generates a printout of each variable within dset that includes the variable name, the units, and an extended description of the variable (if available).</p> <p>Parameters:</p> Name Type Description Default <code>dset</code> <code>Dataset</code> <p>Target dataset. It is possible to call <code>display_vars</code> on an unformatted <code>dset</code> e.g., display_vars(xr.open_dataset(file)), or on a formatted <code>dset</code> e.g., display_vars(get_cmaq_metadata(xr.open_dataset(file))).</p> required <code>var_dsec</code> <code>string</code> <p>Name of the attribute for the xarray.DataArray instances within <code>dset</code> which contains a description of the variable.</p> <code>'var_desc'</code> <code>str_incl</code> <code>string</code> <p>String pattern to use for filtering. Only printout variables which include this pattern.</p> <code>None</code> <code>str_excl</code> <code>string</code> <p>String pattern to use for filtering. Only printout variables which do not include this pattern.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> See Also <p>cmaq.get_cmaq_metadata</p> Source code in <code>downscaler/utils/xarray.py</code> <pre><code>def display_vars(dset, var_dsec=\"var_desc\", str_incl=None, str_excl=None):\n    \"\"\"Displays variables, units, and descriptions of an xarray dataset\n\n    Generates a printout of each variable within dset that includes the\n    variable name, the units, and an extended description of the variable (if\n    available).\n\n    Parameters\n    ----------\n    dset : xarray.Dataset\n        Target dataset. It is possible to call `display_vars` on an unformatted\n        `dset` e.g., display_vars(xr.open_dataset(file)), or on a formatted\n        `dset` e.g., display_vars(get_cmaq_metadata(xr.open_dataset(file))).\n\n    var_dsec : string, default='var_desc'\n        Name of the attribute for the xarray.DataArray instances within `dset`\n        which contains a description of the variable.\n\n    str_incl : string, default=None\n        String pattern to use for filtering. Only printout variables which\n        include this pattern.\n\n    str_excl : string, default=None\n        String pattern to use for filtering. Only printout variables which\n        do not include this pattern.\n\n    Returns\n    -------\n    None\n\n    See Also\n    -------\n    cmaq.get_cmaq_metadata\n    \"\"\"\n\n    data_vars = [x.strip() for x in dset.data_vars]\n\n    # Perform filtering of data variables\n    if str_incl is not None:\n        print(f\"Including Pattern: {str_incl}\")\n        data_vars = [x for x in data_vars if str_incl in x]\n\n    if str_excl is not None:\n        print(f\"Excluding Pattern: {str_excl}\")\n        data_vars = [x for x in data_vars if str_excl not in x]\n\n    var = \"VARNAME\"\n    units = \"UNITS\"\n    desc = \"DESCRIPTION\"\n\n    print(\"-\" * 80)\n    print(f\"| {var:16} | {units:16} | {desc}\")\n    print(\"-\" * 80)\n\n    ct = 1\n\n    for var in data_vars:\n        desc = \"\"\n        units = \"\"\n\n        try:\n            desc = getattr(dset[var], var_dsec)\n        except Exception:\n            pass\n\n        try:\n            units = dset[var].units\n        except Exception:\n            pass\n\n        print(f\"| {var:16} | {units:16} | {desc}\")\n\n        if ct % 6 == 0:\n            print(\"-\" * 80)\n\n        ct += 1\n\n    return None\n</code></pre>"},{"location":"api/xarray/#downscaler.utils.xarray.update_datetime_year","title":"<code>update_datetime_year(ds, updated_year=1901, time_str='time')</code>","text":"<p>Update the year of the time variable of a dataset</p> <p>Given an xarray Dataset or xarray DataArray with a datetime dimension, change the year of the datetime variable. This allows for easier comparisons with other xarray Datasets or DataArrays when the year is unimportant</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>Dataset or DataArray</code> <p>xarray object with a valid datetime dimension</p> required <code>updated_year</code> <code>int</code> <p>This year will replace the year in the original <code>ds</code> datetime coordinate</p> <code>1901</code> <code>time_str</code> <code>str</code> <p>String variable name associated with the datetime dimension</p> <code>\"time\"</code> <p>Returns:</p> Name Type Description <code>ds_update</code> <code>same as `ds`</code> <p>xarray object with updated year associated with the datetime coordinate</p> Source code in <code>downscaler/utils/xarray.py</code> <pre><code>def update_datetime_year(ds, updated_year=1901, time_str=\"time\"):\n    \"\"\"Update the year of the time variable of a dataset\n\n    Given an xarray Dataset or xarray DataArray with a datetime dimension,\n    change the year of the datetime variable. This allows for easier\n    comparisons with other xarray Datasets or DataArrays when the year is\n    unimportant\n\n    Parameters\n    ----------\n\n    ds : xr.Dataset or xr.DataArray\n        xarray object with a valid datetime dimension\n\n    updated_year : int, default=1901\n        This year will replace the year in the original `ds` datetime\n        coordinate\n\n    time_str : str, default=\"time\"\n        String variable name associated with the datetime dimension\n\n    Returns\n    -------\n\n    ds_update : same as `ds`\n        xarray object with updated year associated with the datetime coordinate\n    \"\"\"\n\n    # Convert to a pandas dataframe so can use the datetime.replace(year=YYYY)\n    # method. Save the original year for documentation purposes\n    time = pd.DataFrame({time_str: pd.to_datetime(ds[time_str].data)})\n    original_year = time.iloc[0, 0].year\n    time = time.loc[:, time_str].apply(lambda x: x.replace(year=updated_year))\n\n    # Copy the original xarray object and update the time dimension\n    ds_update = ds.copy()\n    ds_update = ds_update.assign_coords({time_str: time})\n\n    # Only assign the original year attribute if it has not previously been\n    # assigned to avoid overwriting.\n    if \"ORIGINAL_YEAR\" not in ds_update.attrs:\n        ds_update = ds_update.assign_attrs({\"ORIGINAL_YEAR\": original_year})\n\n    return ds_update\n</code></pre>"}]}